spec:
  inputs:
    minimum_python_version:
      default: "3.11"
      description: "Python version for minimum dependency compatibility check"
      type: string
    experimental_python_version:
      default: "3.14"
      description: "Python version for experimental dependency compatibility check"
      type: string

---

# -- GWpy test pipeline

include:
  # platform-specific job templates
  - local: .gitlab/ci/platforms.yml

  # basic test template
  - local: .gitlab/ci/test-job.yml
    inputs:
      job_name: "basic_test"
      pip_cmd: "uv pip"
      pip_options: "--group test"
      pytest_options: >-
        --color yes
        --cov gwpy
        --numprocesses auto
        -ra
        --timeout 1800
        gwpy/

  # full test template
  - local: .gitlab/ci/test-job.yml
    inputs:
      pip_cmd: "uv pip"
      pip_options: "--group dev"
      pytest_options: >-
        --color yes
        --cov gwpy
        --numprocesses auto
        -ra
        --timeout 1800
        gwpy/

  # examples tests
  - local: .gitlab/ci/test-job.yml
    inputs:
      job_name: "examples_test"
      pip_cmd: "uv pip"
      pip_options: "--group dev"
      pytest_options: >-
        --color yes
        --cov gwpy
        --durations 50
        --numprocesses auto
        -ra
        --timeout 1800
        examples/

  # compatibility test template (smaller test suite)
  - local: .gitlab/ci/compatibility.yml
    inputs:
      stage: test
      minimum_python_version: $[[ inputs.minimum_python_version ]]
      experimental_python_version: $[[ inputs.experimental_python_version ]]
      pytest_options: "--color yes --cov gwpy --numprocesses auto gwpy/"

  # measure coverage over all jobs
  - local: .gitlab/ci/coverage.yml

# -- templates

# Bash script to retry a command with exponential backoff
# Inspired by https://medium.com/@obaff/13-bash-only-tricks-you-can-drop-into-any-ci-cd-pipeline-e70ed0caca4c
.retry_sh: &retry_sh |
  retry() {
    local retries=3
    local delay=5
    local exitcode=1
    for ((i=1; i<=retries; i++)); do
      if [ $i -gt 1 ]; then
        sleep "$delay"
        delay=$((delay * 2))
        echo -e "\x1B[93m[retry] Running '$@' [$i/$retries]…\x1B[0m" >&2
      fi
      "$@" && return 0
      exitcode=$?
      if [ "$i" -lt "$retries" ]; then
        echo -e "\x1B[93m[retry] Attempt $i failed. Waiting $delay s…\x1B[0m" >&2
      else
        echo -e "\x1B[93m[retry] Attempt $i failed. No more retries left, returning $exitcode.\x1B[0m" >&2
      fi
    done
    return $exitcode  # propagate failure
  }

.retry_psh: &retry_psh |
  function Retry-Command {
    $retries = 3
    $delay = 5
    $exitcode = 1
    $command = $args
    for ($i = 1; $i -le $retries; $i++) {
      if ($i -gt 1) {
        Start-Sleep -Seconds $delay
        $delay = $delay * 2
        Write-Host "[retry] Running '$command' [$i/$retries]…" -ForegroundColor Yellow
      }
      $commandString = $command -join ' '
      Invoke-Expression $commandString
      if ($LASTEXITCODE -eq 0 -or $?) {
        return 0
      }
      $exitcode = $LASTEXITCODE
      if ($i -lt $retries) {
        Write-Host "[retry] Attempt $i failed. Waiting $delay s…" -ForegroundColor Yellow
      } else {
        Write-Host "[retry] Attempt $i failed. No more retries left, returning $exitcode." -ForegroundColor Yellow
      }
    }
    return $exitcode
  }
  Set-Alias -Name retry -Value Retry-Command

# all development versions
.dev_test:
  needs: []
  extends: .test
  parallel:
    matrix:
      - PYTHON_VERSION:
          - "3.11"
          - "3.12"
          - "3.13"
          - "3.14"

# only well-supported production versions
.prod_test:
  needs: []
  extends: .test
  parallel:
    matrix:
      - PYTHON_VERSION:
          - "3.11"
          - "3.12"
          - "3.13"

.brew:
  extends: .macos
  variables:
    HOMEBREW_CACHE: "$CI_PROJECT_DIR/.cache/brew"
    HOMEBREW_NO_AUTO_UPDATE: 1
  cache:
    key: "brew-${CI_JOB_NAME_SLUG}"
    paths:
      - .cache/brew

.choco:
  extends: .windows
  variables:
    CHOCO_CACHE_DIR: ".cache/choco"
  cache:
    key: "choco-${CI_JOB_NAME_SLUG}"
    paths:
      - .cache/choco

.uv_install: &uv_install
  # install uv
  - *retry_sh
  - retry curl -LsSf https://astral.sh/uv/install.sh | sh -s - -q
  - source ${UV_INSTALL_DIR}/env

.uv_venv: &uv_venv
  # configure a virtual environment for the right Python version
  - uv venv --python ${PYTHON_VERSION}
  - source .venv/bin/activate

.uv_install_windows: &uv_install_windows
  # install uv
  - *retry_psh
  - retry 'powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iex"'
  - $env:PATH += ";$UV_INSTALL_DIR"

.uv_venv_windows: &uv_venv_windows
  # configure a virtual environment for the right Python version
  - uv venv --python ${PYTHON_VERSION}
  - .venv\Scripts\activate

.uv:
  image: "ghcr.io/astral-sh/uv:python$PYTHON_VERSION-bookworm"
  variables:
    # set the cache directory for uv
    UV_CACHE_DIR: "$CI_PROJECT_DIR/.cache/uv"
    UV_INSTALL_DIR: "$CI_PROJECT_DIR/.uv/bin"
  before_script:
    - *uv_install
    - *uv_venv
  after_script:
    - uv cache prune --ci
  cache:
    # cache uv packages
    - key: "uv-${CI_JOB_NAME_SLUG}"
      paths:
        - $UV_CACHE_DIR

.uv_windows:
  extends:
    - .uv
    - .windows
  before_script:
    - *uv_install_windows
    - *uv_venv_windows

# -- basic tests for new branches without MRs
#
# This test matrix provides a sanity check for developers working
# on new branches to ensure functionality before opening an MR and
# running the full (expensive) pipeline. Features:
#   - only runs on Linux on the well-supported Python versions,
#   - doesn't run the examples
#   - doesn't include the various dev dependencies
#

basic_test:
  extends:
    - .prod_test
    - .basic_test
    - .uv
  image: "ghcr.io/astral-sh/uv:python$PYTHON_VERSION-bookworm"
  rules:
    - !reference [.rules_basic_test, rules]

# -- python tests
#
# Full automated test suite on all supported Python versions for
# multiple platforms.
#
# On macOS and Windows, we only test the well-supported Python versions,
# ignore the old versions dopped by NEP29, and the latest versions that
# don't have full compatibility across the dependencies (yet).
#

# Linux
python_test_linux:
  extends:
    - .dev_test
    - .uv
    - .linux
  rules:
    - !reference [.linux, rules]
    - !reference [.rules_full_test, rules]
  before_script:
    # don't need to install uv, it comes with the image
    - *uv_venv

# macOS
python_test_macos:
  extends:
    - .prod_test
    - .uv
    - .macos
  rules:
    - !reference [.macos, rules]
    - !reference [.rules_full_test, rules]

# Windows
python_test_windows:
  extends:
    - .prod_test
    - .uv_windows
  rules:
    - !reference [.windows, rules]
    - !reference [.rules_full_test, rules]

# anchors for needs statements

.needs_python_test_linux:
  needs:
    - job: python_test_linux
      artifacts: false
      parallel:
        matrix:
          - PYTHON_VERSION: ['$[[ matrix.PYTHON_VERSION ]]']

.needs_python_test_macos:
  needs:
    - job: python_test_macos
      artifacts: false
      parallel:
        matrix:
          - PYTHON_VERSION: ['$[[ matrix.PYTHON_VERSION ]]']

.needs_python_test_windows:
  needs:
    - job: python_test_windows
      artifacts: false
      parallel:
        matrix:
          - PYTHON_VERSION: ['$[[ matrix.PYTHON_VERSION ]]']

# -- conda tests
#
# Full test suite using Conda to provide the widest possible set of
# dependencies
#
# Runs on the same platforms and Python versions as the full Python
# tests defined above
#

.conda_create_test_env:
  before_script:
    # install rattler solver
    - retry conda install --quiet --yes --name base --channel conda-forge
        "conda-rattler-solver>=0.0.5"
    - conda config --system --set solver rattler
    - conda info --all
    # use pip2conda to solve (sort of) the test environment
    - retry uvx --with "pip2conda>=0.9.0"
      pip2conda
        --all-extras
        --all-groups
        --output environment.txt
        --python-version ${PYTHON_VERSION}
    - cat environment.txt
    # create the test environment
    - retry conda create --quiet --yes --name test --file environment.txt
    - conda list --name test
    - conda activate test

.conda_test:
  extends:
    - .prod_test
    - .uv
  stage: conda
  variables:
    CONDA_PKGS_DIRS: "${CI_PROJECT_DIR}/.cache/conda/pkgs"
  cache:
    - !reference [.uv, cache]
    - key: "conda-${CI_JOB_NAME_SLUG}"
      paths:
        - .cache/conda/pkgs/*.conda

# Linux
conda_test_linux:
  extends:
    - .conda_test
    - .linux
    - .needs_python_test_linux
  rules:
    - !reference [.linux, rules]
    - !reference [.rules_full_test, rules]
  image: quay.io/condaforge/miniforge3
  variables:
    DEBIAN_FRONTEND: noninteractive
  before_script:
    - *retry_sh
    # install latex packages
    - apt-get -yqq update && apt-get install -yqq --no-install-recommends
        cm-super-minimal
        dvipng
        texlive-fonts-recommended
        texlive-latex-extra
    # install curl
    - apt-get -yqq update && apt-get -yqq install curl
    # install uv
    - *uv_install
    # init conda
    - . $(conda info --base)/etc/profile.d/conda.sh
    # create the test environment using conda, uv, and pip2conda
    - !reference [.conda_create_test_env, before_script]
    # initialise credentials
    - bash -ex .gitlab/ci/init-creds.sh

# macOS
conda_test_macos:
  extends:
    - .conda_test
    - .macos
    - .needs_python_test_macos
  rules:
    - !reference [.macos, rules]
    - !reference [.rules_full_test, rules]
  before_script:
    - *retry_sh
    # install miniforge
    - retry curl -L -O "https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh"
    - retry bash Miniforge3-$(uname)-$(uname -m).sh -b -p "$CI_PROJECT_DIR/miniforge3"
    - . $CI_PROJECT_DIR/miniforge3/etc/profile.d/conda.sh
    # then do the same init as Linux
    - !reference [conda_test_linux, before_script]
  cache:
    # cache uv/conda packages
    - !reference [.conda_test, cache]

# Windows
conda_test_windows:
  # allow windows a bit more time for provisioning
  timeout: 90m
  extends:
    - .conda_test
    - .choco
    - .uv_windows
    - .needs_python_test_windows
  rules:
    - !reference [.windows, rules]
    - !reference [.rules_full_test, rules]
  before_script:
    - *retry_psh
    # install uv
    - *uv_install_windows
    # install miniforge using choco
    - retry choco install
        --cache $CHOCO_CACHE_DIR
        --yes
        miniforge3
    - $env:PATH += ";C:\tools\miniforge3\Scripts;C:\tools\miniforge3"
    - conda init powershell
    - . C:\tools\miniforge3\shell\condabin\conda-hook.ps1
    # create the test environment using conda, uv, and pip2conda
    - !reference [.conda_create_test_env, before_script]
  cache:
    # cache conda packages
    - !reference [.conda_test, cache]
    # and choco packages
    - !reference [.choco, cache]

# -- examples tests
#
# Full development environment running the examples/ scripts
#
# These are allowed to fail, as they are not critical, and failures are
# often due to transient network issues downloading data, or issues with
# third-party services.
#
# However, they are used in the documentation, so we want to keep an eye
# on them.
#

.examples:
  script: !reference [.examples_test, script]
  allow_failure: true

examples_test_linux:
  extends:
    - conda_test_linux
    - .examples

examples_test_macos:
  extends:
    - conda_test_macos
    - .examples

examples_test_windows:
  extends:
    - conda_test_windows
    - .examples
